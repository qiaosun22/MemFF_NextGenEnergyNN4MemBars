{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [24:58<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [26:49<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accu: 96.42399549484253\n",
      "test accu: 94.80999708175659\n",
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1], device='cuda:0') tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from train_utils import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "batchsize = 100\n",
    "#================================\n",
    "# Quantization levels\n",
    "#================================\n",
    "img_half_level = 4\n",
    "weight_bit = 8 \n",
    "output_bit = 6\n",
    "isint = 0\n",
    "clamp_std = 0\n",
    "noise_scale = 5e-2\n",
    "\n",
    "def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n",
    "\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.1307,), (0.3081,)),\n",
    "        Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST('./data/', train=True,\n",
    "              download=True,\n",
    "              transform=transform),\n",
    "        batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        MNIST('./data/', train=False,\n",
    "              download=True,\n",
    "              transform=transform),\n",
    "        batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def overlay_y_on_x(x, y):\n",
    "    \"\"\"\n",
    "    Replace the first 10 pixels of data [x] with one-hot-encoded label [y]\n",
    "    \"\"\"\n",
    "    x_ = x.clone()\n",
    "    x_[:, :10] *= 0.0\n",
    "    x_[range(x.shape[0]), y] = x.max()\n",
    "    return x_\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for d in range(len(dims) - 1):\n",
    "            self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n",
    "\n",
    "    def predict(self, x): \n",
    "        # 这个predict方法是理解ff方法的关键，它不是像普通的predict方法一样，输入一个样本，输出一个长度为num_cls的softmax预测向量\n",
    "        # 而是一个样本反复输入这个网络num_cls次，把每种带标签的可能都计算一个goodness，也就是这个数据是好数据的可能性，找出最高goodness的就是预测类别\n",
    "        goodness_per_label = []\n",
    "        for label in range(10): # 对每一个标签进行预测\n",
    "            h = overlay_y_on_x(x, label) # h是输入x和标签label的叠加\n",
    "            goodness = [] # goodness是一个列表，里面存放了每一层的结果向量的均方\n",
    "            for layer in self.layers: # 对每一层进行前传\n",
    "                h = layer(h) # h是每一层的输出\n",
    "                goodness += [h.pow(2).mean(1)] # goodness是每一层的结果向量的均方。h.pow(2)是h的每一个元素的平方，mean(1)是对每一行求均值\n",
    "            goodness_per_label += [sum(goodness).unsqueeze(1)] # goodness_per_label是每一层的结果向量的均方的和\n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1) # goodness_per_label是每一层的结果向量的均方的和的列表\n",
    "        return goodness_per_label.argmax(1) # 返回的是goodness_per_label中每一行最大值的索引，也就是说，返回的是每一行最大值的列索引\n",
    "\n",
    "    def train(self, li_epochs, li_lr): #, x_pos, x_neg): # 这个train方法是对整个网络进行训练，训练的目标是让正样本的结果向量的均方上升，负样本的结果向量的均方下降\n",
    "        x, y = next(iter(train_loader))\n",
    "        x, _ = my.data_quantization_sym(x, half_level=img_half_level)\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        x_pos = overlay_y_on_x(x, y)\n",
    "        # rnd = torch.randperm(x.size(0)) # 生成一个从0到n-1的随机整数序列。\n",
    "        # x_neg = overlay_y_on_x(x, y[rnd])\n",
    "        y_rnd = y.clone()\n",
    "        for i, y_i in enumerate(y):\n",
    "            li = list(range(10))\n",
    "            li.remove(y_i)\n",
    "            j = np.random.choice(li)\n",
    "            y_rnd[i] = j\n",
    "\n",
    "        x_neg = overlay_y_on_x(x, y_rnd)\n",
    "\n",
    "        h_pos, h_neg = x_pos, x_neg # h_pos和h_neg是正样本和负样本的输入\n",
    "        for i, layer in enumerate(self.layers): # 对每一层进行训练\n",
    "            print('training layer', i, '...') # 这里的i是层数\n",
    "            h_pos, h_neg = layer.train(h_pos, h_neg, num_epochs=li_epochs[i], lr=li_lr[i]) # 对每一层进行训练，得到了正样本和负样本的结果向量，这个结果向量是该层的输出，也是下一层的输入\n",
    "            # 也就是说，这个训练的过程中，正样本在前传过程中得到的每一层输出都被认为是正的，负样本在前传过程中得到的每一层输出都被认为是负的，也就是说，出身决定一切\n",
    "\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 bias=True, device=None, dtype=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=8e-3)\n",
    "        self.threshold = 2.0\n",
    "        # self.num_epochs = num_epochs # 训练的次数是1000次\n",
    "        # self.linear = my.Linear_quant_noise(in_features, out_features, weight_bit=weight_bit, output_bit=output_bit, isint=isint, clamp_std=clamp_std, noise_scale=noise_scale, bias=True)\n",
    "        self.weight_bit = weight_bit\n",
    "        self.output_bit = output_bit\n",
    "        self.isint = 0\n",
    "        self.clamp_std = 0\n",
    "        self.noise_scale = 0\n",
    "        self.weight_half_level = 2 ** weight_bit / 2 - 1\n",
    "        self.output_half_level = 2 ** output_bit / 2 - 1\n",
    "        # self.linear = nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "        self.lossli = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x.shape\", x.shape)\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)  # 这个是对输入做了归一化，使得输入的模长为1，这在论文里有解释\n",
    "        # print(\"x_norm.shape\", x_direction.shape)\n",
    "        # x_direction = x / x.max()\n",
    "        # self.weight_, self.bias_ = my.Weight_Quant_Noise.apply(self.weight, self.bias,\n",
    "        #                                     self.weight_half_level, \n",
    "        #                                     self.isint, self.clamp_std,\n",
    "        #                                     self.noise_scale\n",
    "        #                                     )\n",
    "        self.weight_, self.bias_ = self.weight, self.bias\n",
    "        x_direction = self.relu(\n",
    "            # torch.mm(x_direction, self.weight.T) +\n",
    "            # self.bias.unsqueeze(0) # 这个是对输入做了最基本的前向传播，得到了结果向量4\n",
    "            # self.linear(x_direction)\n",
    "            F.linear(x_direction, self.weight_, self.bias_)\n",
    "            ) # 注意，在前传之后，随即使用了relu激活函数，这意味着每一层的所有激活值都是非负的\n",
    "        \n",
    "        # x = my.Feature_Quant.apply(x, self.output_half_level, self.isint)\n",
    "        # print(\"x_direction.shape\", x_direction.shape)\n",
    "\n",
    "        return x_direction\n",
    "\n",
    "    def train(self, x_pos, x_neg, num_epochs=4000000, lr=8e-3):\n",
    "        opt = Adam(self.parameters(), lr=lr)\n",
    "        # 训练其实就是对每一层分别进行训练，训练的目标是让正样本的结果向量的均方上升，负样本的结果向量的均方下降\n",
    "        # 每一层的forward方法定义如上一个函数，这里的train方法定义了训练的过程\n",
    "        # print(\"x_pos.shape\", x_pos.shape)\n",
    "        for i in tqdm(range(num_epochs)):\n",
    "            # minibatch\n",
    "            bz = 100\n",
    "            for j in range(0, x_pos.size(0), bz):\n",
    "                \n",
    "                # print(j)\n",
    "                # mask = torch.randperm(x_pos.size(0))[j: j+bz]\n",
    "                # mask = [j: j+bz]\n",
    "                h_pos = x_pos[j: j+bz] # 随机采样1000个正样本\n",
    "                h_neg = x_neg[j: j+bz] # 随机采样1000个负样本\n",
    "\n",
    "\n",
    "                # for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
    "                #     visualize_sample(data, name)\n",
    "                \n",
    "                # print(self.forward(x_pos).pow(2), self.forward(x_pos).pow(2).shape)\n",
    "                g_pos = self.forward(h_pos).pow(2).mean(1) # g_pos 是正样本x_pos在该层前向传播得到的结果向量的均方\n",
    "                g_neg = self.forward(h_neg).pow(2).mean(1) # g_neg 是负样本x_neg在该层前向传播得到的结果向量的均方\n",
    "                # 论文关于使用L2范数来度量的理由：\n",
    "                # There are two main reasons for using the squared length of the activity vector as the goodness function.\n",
    "                # First, it has very simple derivatives. Second, layer normalization removes all trace of the goodness.\n",
    "                \n",
    "                # The following loss pushes pos (neg) samples to\n",
    "                # values larger (smaller) than the self.threshold.\n",
    "                # 随着训练过程，loss下降，g_pos将上升，g_neg将下降\n",
    "                loss = torch.log(1 + torch.exp(torch.cat([\n",
    "                    -g_pos + self.threshold,\n",
    "                    g_neg - self.threshold]))).mean() # loss = [log(1+exp(-(g_pos-threshold))) + log(1+exp(g_neg-threshold))] / 2\n",
    "                # print(loss)\n",
    "                self.lossli.append(loss.item())  # save loss\n",
    "                \n",
    "                # this backward just compute the derivative and hence\n",
    "                # is not considered backpropagation.\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                # self.opt.step()\n",
    "                # self.opt.zero_grad()\n",
    "                    \n",
    "            # optimizer.step()\n",
    "            # optimizer.zero_grad()\n",
    "            # if i<4:\n",
    "            #     # print(a)\n",
    "            #     # 查看累积的梯度值\n",
    "            #     # print(self.parameters())\n",
    "            #     for param in self.parameters():\n",
    "            #         print(param.grad)\n",
    "                # print(loss)\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            # 关于这里为什么能够work：\n",
    "            # 1. loss是权重的函数，loss的核心思想是让g_pos上升，g_neg下降\n",
    "            # 2. g_pos和g_neg是x_pos和x_neg的函数，x_pos和x_neg反映了客观世界，是这样要学习的对象。有了x_pos和x_neg，就能够计算出g_pos和g_neg，有了g_pos和g_neg，就能够计算出loss\n",
    "            # 3. 通过loss.backward()，计算loss对权重的梯度，使得loss下降，g_pos上升，g_neg下降\n",
    "            # 4. 通过self.opt.step()，更新了self.weight和self.bias\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
    "\n",
    "    \n",
    "# def visualize_sample(data, name='', idx=0):\n",
    "#     reshaped = data[idx].cpu().reshape(28, 28)\n",
    "#     plt.figure(figsize = (4, 4))\n",
    "#     plt.title(name)\n",
    "#     plt.imshow(reshaped, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(1234)\n",
    "    train_loader, test_loader = MNIST_loaders(train_batch_size=50000, test_batch_size=10000)\n",
    "\n",
    "    net = Net([784, 500, 500])\n",
    "    x, y = next(iter(train_loader))\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    # x_pos = overlay_y_on_x(x, y)\n",
    "    # # rnd = torch.randperm(x.size(0)) # 生成一个从0到n-1的随机整数序列。\n",
    "    # # x_neg = overlay_y_on_x(x, y[rnd])\n",
    "    # y_rnd = y.clone()\n",
    "    # for i, y_i in enumerate(y):\n",
    "    #     li = list(range(10))\n",
    "    #     li.remove(y_i)\n",
    "    #     j = np.random.choice(li)\n",
    "    #     y_rnd[i] = j\n",
    "\n",
    "    # x_neg = overlay_y_on_x(x, y_rnd)\n",
    "    # # for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
    "    # #     visualize_sample(data, name)\n",
    "    \n",
    "    net.train(li_epochs=[10000, 10000], li_lr=[8e-3, 8e-3])#x_pos, x_neg)\n",
    "\n",
    "    print('train accu:', 100. * net.predict(x).eq(y).float().mean().item())\n",
    "\n",
    "    x_te, y_te = next(iter(test_loader))\n",
    "    x_te, y_te = x_te.cuda(), y_te.cuda()\n",
    "\n",
    "    print('test accu:', 100. * net.predict(x_te).eq(y_te).float().mean().item())\n",
    "\n",
    "    print(net.predict(x_te)[:30], y_te[:30])\n",
    "\n",
    "    plt.plot(net.layers[0].lossli)\n",
    "    plt.plot(net.layers[1].lossli)\n",
    "    plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from train_utils import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "batchsize = 100\n",
    "#================================\n",
    "# Quantization levels\n",
    "#================================\n",
    "img_half_level = 4\n",
    "weight_bit = 8 \n",
    "output_bit = 6\n",
    "isint = 0\n",
    "clamp_std = 0\n",
    "noise_scale = 5e-2\n",
    "\n",
    "def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n",
    "\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.1307,), (0.3081,)),\n",
    "        Lambda(lambda x: torch.flatten(x))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        MNIST('./data/', train=True,\n",
    "              download=True,\n",
    "              transform=transform),\n",
    "        batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        MNIST('./data/', train=False,\n",
    "              download=True,\n",
    "              transform=transform),\n",
    "        batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def overlay_y_on_x(x, y):\n",
    "    \"\"\"\n",
    "    Replace the first 10 pixels of data [x] with one-hot-encoded label [y]\n",
    "    \"\"\"\n",
    "    x_ = x.clone()\n",
    "    x_[:, :10] *= 0.0\n",
    "    x_[range(x.shape[0]), y] = x.max()\n",
    "    return x_\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, dims):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for d in range(len(dims) - 1):\n",
    "            self.layers += [Layer(dims[d], dims[d + 1]).cuda()]\n",
    "\n",
    "    def predict(self, x): \n",
    "        # 这个predict方法是理解ff方法的关键，它不是像普通的predict方法一样，输入一个样本，输出一个长度为num_cls的softmax预测向量\n",
    "        # 而是一个样本反复输入这个网络num_cls次，把每种带标签的可能都计算一个goodness，也就是这个数据是好数据的可能性，找出最高goodness的就是预测类别\n",
    "        goodness_per_label = []\n",
    "        for label in range(10): # 对每一个标签进行预测\n",
    "            h = overlay_y_on_x(x, label) # h是输入x和标签label的叠加\n",
    "            goodness = [] # goodness是一个列表，里面存放了每一层的结果向量的均方\n",
    "            for layer in self.layers: # 对每一层进行前传\n",
    "                h = layer(h) # h是每一层的输出\n",
    "                goodness += [h.pow(2).mean(1)] # goodness是每一层的结果向量的均方。h.pow(2)是h的每一个元素的平方，mean(1)是对每一行求均值\n",
    "            goodness_per_label += [sum(goodness).unsqueeze(1)] # goodness_per_label是每一层的结果向量的均方的和\n",
    "        goodness_per_label = torch.cat(goodness_per_label, 1) # goodness_per_label是每一层的结果向量的均方的和的列表\n",
    "        return goodness_per_label.argmax(1) # 返回的是goodness_per_label中每一行最大值的索引，也就是说，返回的是每一行最大值的列索引\n",
    "\n",
    "    def train(self): #, x_pos, x_neg): # 这个train方法是对整个网络进行训练，训练的目标是让正样本的结果向量的均方上升，负样本的结果向量的均方下降\n",
    "        x, y = next(iter(train_loader))\n",
    "        x, _ = my.data_quantization_sym(x, half_level=img_half_level)\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        x_pos = overlay_y_on_x(x, y)\n",
    "        # rnd = torch.randperm(x.size(0)) # 生成一个从0到n-1的随机整数序列。\n",
    "        # x_neg = overlay_y_on_x(x, y[rnd])\n",
    "        y_rnd = y.clone()\n",
    "        for i, y_i in enumerate(y):\n",
    "            li = list(range(10))\n",
    "            li.remove(y_i)\n",
    "            j = np.random.choice(li)\n",
    "            y_rnd[i] = j\n",
    "\n",
    "        x_neg = overlay_y_on_x(x, y_rnd)\n",
    "\n",
    "        h_pos, h_neg = x_pos, x_neg # h_pos和h_neg是正样本和负样本的输入\n",
    "        for i, layer in enumerate(self.layers): # 对每一层进行训练\n",
    "            print('training layer', i, '...') # 这里的i是层数\n",
    "            h_pos, h_neg = layer.train(h_pos, h_neg) # 对每一层进行训练，得到了正样本和负样本的结果向量，这个结果向量是该层的输出，也是下一层的输入\n",
    "            # 也就是说，这个训练的过程中，正样本在前传过程中得到的每一层输出都被认为是正的，负样本在前传过程中得到的每一层输出都被认为是负的，也就是说，出身决定一切\n",
    "\n",
    "\n",
    "class Layer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features,\n",
    "                 bias=True, device=None, dtype=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.opt = Adam(self.parameters(), lr=8e-3)\n",
    "        self.threshold = 2.0\n",
    "        self.num_epochs = 2000 # 训练的次数是1000次\n",
    "        # self.linear = my.Linear_quant_noise(in_features, out_features, weight_bit=weight_bit, output_bit=output_bit, isint=isint, clamp_std=clamp_std, noise_scale=noise_scale, bias=True)\n",
    "        self.weight_bit = weight_bit\n",
    "        self.output_bit = output_bit\n",
    "        self.isint = 0\n",
    "        self.clamp_std = 0\n",
    "        self.noise_scale = 0\n",
    "        self.weight_half_level = 2 ** weight_bit / 2 - 1\n",
    "        self.output_half_level = 2 ** output_bit / 2 - 1\n",
    "        # self.linear = nn.Linear(in_features, out_features, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)  # 这个是对输入做了归一化，使得输入的模长为1，这在论文里有解释\n",
    "        # x_direction = x / x.max()\n",
    "        self.weight_, self.bias_ = my.Weight_Quant_Noise.apply(self.weight, self.bias,\n",
    "                                            self.weight_half_level, \n",
    "                                            self.isint, self.clamp_std,\n",
    "                                            self.noise_scale\n",
    "                                            )\n",
    "        x_direction = self.relu(\n",
    "            # torch.mm(x_direction, self.weight.T) +\n",
    "            # self.bias.unsqueeze(0) # 这个是对输入做了最基本的前向传播，得到了结果向量4\n",
    "            # self.linear(x_direction)\n",
    "            F.linear(x_direction, self.weight_, self.bias_)\n",
    "            ) # 注意，在前传之后，随即使用了relu激活函数，这意味着每一层的所有激活值都是非负的\n",
    "        \n",
    "        x = my.Feature_Quant.apply(x, self.output_half_level, self.isint)\n",
    "\n",
    "        return x_direction\n",
    "\n",
    "    def train(self, x_pos, x_neg):\n",
    "        # 训练其实就是对每一层分别进行训练，训练的目标是让正样本的结果向量的均方上升，负样本的结果向量的均方下降\n",
    "        # 每一层的forward方法定义如上一个函数，这里的train方法定义了训练的过程\n",
    "        for i in tqdm(range(self.num_epochs)):\n",
    "            # minibatch\n",
    "            # bz = 100\n",
    "            # for j in range(0, x_pos.size(0), bz):\n",
    "            #     mask = torch.randperm(x_pos.size(0))[:bz]\n",
    "            #     x_pos = x_pos[mask] # 随机采样1000个正样本\n",
    "            #     x_neg = x_neg[mask] # 随机采样1000个负样本\n",
    "\n",
    "\n",
    "                # for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
    "                #     visualize_sample(data, name)\n",
    "                \n",
    "                # print(self.forward(x_pos).pow(2), self.forward(x_pos).pow(2).shape)\n",
    "                g_pos = self.forward(x_pos).pow(2).mean(1) # g_pos 是正样本x_pos在该层前向传播得到的结果向量的均方\n",
    "                g_neg = self.forward(x_neg).pow(2).mean(1) # g_neg 是负样本x_neg在该层前向传播得到的结果向量的均方\n",
    "                # 论文关于使用L2范数来度量的理由：\n",
    "                # There are two main reasons for using the squared length of the activity vector as the goodness function.\n",
    "                # First, it has very simple derivatives. Second, layer normalization removes all trace of the goodness.\n",
    "                \n",
    "                # The following loss pushes pos (neg) samples to\n",
    "                # values larger (smaller) than the self.threshold.\n",
    "                # 随着训练过程，loss下降，g_pos将上升，g_neg将下降\n",
    "                loss = torch.log(1 + torch.exp(torch.cat([\n",
    "                    -g_pos + self.threshold,\n",
    "                    g_neg - self.threshold]))).mean() # loss = [log(1+exp(-(g_pos-threshold))) + log(1+exp(g_neg-threshold))] / 2\n",
    "                # print(loss)\n",
    "                self.opt.zero_grad()\n",
    "                # this backward just compute the derivative and hence\n",
    "                # is not considered backpropagation.\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                # 关于这里为什么能够work：\n",
    "                # 1. loss是权重的函数，loss的核心思想是让g_pos上升，g_neg下降\n",
    "                # 2. g_pos和g_neg是x_pos和x_neg的函数，x_pos和x_neg反映了客观世界，是这样要学习的对象。有了x_pos和x_neg，就能够计算出g_pos和g_neg，有了g_pos和g_neg，就能够计算出loss\n",
    "                # 3. 通过loss.backward()，计算loss对权重的梯度，使得loss下降，g_pos上升，g_neg下降\n",
    "                # 4. 通过self.opt.step()，更新了self.weight和self.bias\n",
    "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
    "\n",
    "    \n",
    "# def visualize_sample(data, name='', idx=0):\n",
    "#     reshaped = data[idx].cpu().reshape(28, 28)\n",
    "#     plt.figure(figsize = (4, 4))\n",
    "#     plt.title(name)\n",
    "#     plt.imshow(reshaped, cmap=\"gray\")\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(1234)\n",
    "    train_loader, test_loader = MNIST_loaders(train_batch_size=50000, test_batch_size=10000)\n",
    "\n",
    "    net = Net([784, 500, 500])\n",
    "    x, y = next(iter(train_loader))\n",
    "    x, y = x.cuda(), y.cuda()\n",
    "    # x_pos = overlay_y_on_x(x, y)\n",
    "    # # rnd = torch.randperm(x.size(0)) # 生成一个从0到n-1的随机整数序列。\n",
    "    # # x_neg = overlay_y_on_x(x, y[rnd])\n",
    "    # y_rnd = y.clone()\n",
    "    # for i, y_i in enumerate(y):\n",
    "    #     li = list(range(10))\n",
    "    #     li.remove(y_i)\n",
    "    #     j = np.random.choice(li)\n",
    "    #     y_rnd[i] = j\n",
    "\n",
    "    # x_neg = overlay_y_on_x(x, y_rnd)\n",
    "    # # for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
    "    # #     visualize_sample(data, name)\n",
    "    \n",
    "    net.train()#x_pos, x_neg)\n",
    "\n",
    "    print('train error:', 1.0 - net.predict(x).eq(y).float().mean().item())\n",
    "\n",
    "    x_te, y_te = next(iter(test_loader))\n",
    "    x_te, y_te = x_te.cuda(), y_te.cuda()\n",
    "\n",
    "    print('test error:', 1.0 - net.predict(x_te).eq(y_te).float().mean().item())\n",
    "\n",
    "    print(net.predict(x_te)[:30], y_te[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1267660856246948,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].lossli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer 0 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:12<00:00, 30812.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training layer 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:12<00:00, 31412.02it/s]\n"
     ]
    }
   ],
   "source": [
    "    net.train()#x_pos, x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.8745400011539459\n"
     ]
    }
   ],
   "source": [
    "    print('train error:', 1.0 - net.predict(x).eq(y).float().mean().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forward",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
